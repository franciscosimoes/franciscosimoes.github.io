%% 2022 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@ARTICLE{10003228,
  author={Moreira, Catarina and Simões, Francisco P. M. and Lee, Mark J. W. and Zorzal, Ezequiel R. and Lindeman, Robert W. and Pereira, João Madeiras and Johnsen, Kyle and Jorge, Joaquim},
  journal={IEEE Access}, 
  title={Toward VR in VR: Assessing Engagement and Social Interaction in a Virtual Conference}, 
  year={2023},
  volume={11},
  number={},
  pages={1906-1922},
  weblink={10.1109/ACCESS.2022.3233312},
  img = {images/paper_thumbnails/fpms_accfpms_access22.jpg},
  }

@article{DACUNHA2022224,
title = {The impact of domain randomization on cross-device monocular deep 6DoF detection},
journal = PRL,
volume = {159},
pages = {224-231},
year = {2022},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2022.04.008},
weblink = {https://www.sciencedirect.com/science/article/pii/S0167865522001040},
img = {images/paper_thumbnails/kbc_prl22.jpg},
author = {Kelvin B. {da Cunha} and Caio Brito and Lucas Valença and Lucas Figueiredo and Francisco Simões and Veronica Teichrieb},
keywords = {6DoF pose estimation, Domain randomization, Deep learning, Cross-device},
abstract = {This work evaluates the use of synthetic data to train deep 6DoF pose estimation models that use a monocular RGB camera as input. We have compared different training strategies combining real and synthetic data (with domain randomization) to investigate how to better handle real-world challenges. We show that it is possible to obtain accurate models using less real data and suggest how to utilize this strategy. In this work, we have captured and made available two datasets: one real and one synthetic, totaling over 110,000 annotated frames. These datasets are organized according to the different cameras used and the challenges present in the sequences, all featuring textureless 3D printed objects. We also show that synthetic data can help models generalize, handling challenges such as fast motion, occlusion, illumination changes, color variation, scale changes, and unexpected geometry. Finally, we evaluated 70 different models to understand how a model trained for one camera sensor performs when used with a different sensor. To this end, we also suggest how to handle this challenge better by using synthetic simulations to supplement training.}
}

@article{LIMA_mva22,
title = {3D pedestrian localization using multiple cameras: a generalizable approach},
journal = MVA,
volume = {33},
pages = {61},
year = {2022},
issn = {1432-1769},
doi = {https://doi.org/10.1007/s00138-022-01323-9},
weblink = {https://doi.org/10.1007/s00138-022-01323-9},
img = {images/paper_thumbnails/lima_mva22.jpg},
author = {do Monte Lima, Jo{\~a}o Paulo Silva and Roberto, Rafael and Figueiredo, Lucas and Sim{\~o}es, Francisco Paulo Magalh{\~a}es and Thomas, Diego and Uchiyama, Hideaki and Teichrieb, Veronica},
keywords = {Pedestrian detection,3D location,Multi-camera,Generalizable},
abstract = {Pedestrian detection is a critical problem in many areas, such as smart cities, surveillance, monitoring, autonomous driving, and robotics. AI-based methods have made tremendous progress in the field in the last few years, but good performance is limited to data that match the training datasets. We present a multi-camera 3D pedestrian detection method that does not need to be trained using data from the target scene. The core idea of our approach consists in formulating consistency in multiple views as a graph clique cover problem. We estimate pedestrian ground location on the image plane using a novel method based on human body poses and person’s bounding boxes from an off-the-shelf monocular detector. We then project these locations onto the ground plane and fuse them with a new formulation of a clique cover problem from graph theory. We propose a new vertex ordering strategy to define fusion priority based on both detection distance and vertex degree. We also propose an optional step for exploiting pedestrian appearance during fusion by using a domain-generalizable person re-identification model. Finally, we compute the final 3D ground coordinates of each detected pedestrian with a method based on keypoint triangulation. We evaluated the proposed approach on the challenging WILDTRACK and MultiviewX datasets. Our proposed method significantly outperformed state of the art in terms of generalizability. It obtained a MODA that was approximately 15% and 2% better than the best existing generalizable detection technique on WILDTRACK and MultiviewX, respectively.}
}

%% 2021 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{lima_cvprw21,
  author={Lima, João Paulo and Roberto, Rafael and Figueiredo, Lucas and Simões, Francisco and Teichrieb, Veronica},
  title={{Generalizable Multi-Camera 3D Pedestrian Detection}},
  booktitle=CVPRW,
  year=2021,
  img = {images/paper_thumbnails/lima_cvprw21.jpg},
  pdf = {files/papers/fpms/paper_lima_cvprw21.pdf},
  weblink = {files/papers/fpms/paper_lima_cvprw21.pdf},
  note = {Oral}
}

@article{BUARQUEVIEIRAESILVA21,
  title = {A fluid simulation system based on the MPS method},
  journal = COMPHY,
  volume = {258},
  pages = {107572},
  year = {2021},
  issn = {0010-4655},
  doi = {https://doi.org/10.1016/j.cpc.2020.107572},
  url = {https://www.sciencedirect.com/science/article/pii/S0010465520302745},
  author = {André Vieira-e-Silva and Caio Brito and Francisco Simões and Veronica Teichrieb},
  keywords = {MPS, Framework, Numerical improvements, Fluid models, Parallelization},
  abstract = {Fluid flow simulation is a highly active area with applications in a wide range of engineering problems and interactive systems. Meshless methods like the Moving Particle Semi-implicit (MPS) are a great alternative to deal efficiently with large deformations and free-surface flow. However, mesh-based approaches can achieve higher numerical precision than particle-based techniques with a performance cost. This paper presents a numerically stable and parallelized system that benefits from advances in the literature and parallel computing to obtain an adaptable MPS method. The proposed technique can simulate liquids using different approaches, such as two ways to calculate the particles’ pressure, turbulent flow, and multiphase interaction. The method is evaluated under traditional tests cases presenting comparable results to recent techniques. This work integrates the previously mentioned advances into a single solution, which can switch on improvements, such as better momentum conservation and less spurious pressure oscillations, through a graphical interface. The code is entirely open-source under the GPLv3 free software license. The GPU-accelerated code reached speedups ranging from 3 to 43 times, depending on the total number of particles. The simulation runs at one fps for a case with approximately 200,000 particles.
  Program summary
  Program Title: Voxar MPS CPC Library link to program files: http://dx.doi.org/10.17632/49f6djvhjk.1 Licensing provisions: GNU General Public License version 3 Programming language: C++ and CUDA Nature of problem: The Voxar MPS code has been developed to study the flow of incompressible fluids that requires high computational cost. Solution method: Voxar MPS is an implementation of the Moving Particle Semi-implicit, a Lagrangian meshless particle method for incompressible fluids.},
  weblink = {https://www.sciencedirect.com/science/article/abs/pii/S0010465520302745},
  img = {images/paper_thumbnails/comphy21.gif}
}

@INPROCEEDINGS{valenca21,
  author={Lucas Valença and Luca Silva and Thiago Chaves and Arlindo Gomes and Lucas Figueiredo and Lucio Cossio and Sebastien Tandel and João Lima and Francisco Simões and Veronica Teichrieb},
  title={Real-time Monocular 6DoF Tracking of Textureless Objects using Photometrically-enhanced Edges},
  booktitle=VISAPP,
  year={2021},
  doi={10.5220/0010348707630773},
  isbn={978-989-758-488-6},
  pdf = {files/papers/fpms/paper_valenca_visapp21.pdf},
  weblink = {https://www.scitepress.org/Papers/2021/103487/},
  img = {images/paper_thumbnails/valenca_visapp21.png}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@INPROCEEDINGS{felix20,
  author={Heitor Felix and Walber M. Rodrigues and David Macêdo and Francisco Simões and Adriano L. I. Oliveira and Veronica Teichrieb and Cleber Zanchettin},
  booktitle=IJCNN, 
  title={Squeezed Deep 6DoF Object Detection using Knowledge Distillation}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  doi={10.1109/IJCNN48605.2020.9207459},
  weblink = {https://ieeexplore.ieee.org/document/9207459},
  img = {images/paper_thumbnails/felix_ijcnn20.jpg}
}

@INPROCEEDINGS{cunha20,
  author={Kelvin da Cunha and Caio Brito and Lucas Valença and Francisco Simões and Veronica Teichrieb},
  booktitle=SIBGRAPI, 
  title={A Study on the Impact of Domain Randomization for Monocular Deep 6DoF Pose Estimation}, 
  year={2020},
  pages={332-339},
  doi={10.1109/SIBGRAPI51738.2020.00052},
  weblink = {https://ieeexplore.ieee.org/document/9266023},
  img = {images/paper_thumbnails/cunha_sibgrapi20.png}
}

@misc{souza20,
  title={Watermarked image signal with varied watermark strengths},
  author={Lucio Cossio and Sebastien Tandel and Robert Taylor and Thiago Souza and Francisco Simões and Heitor Felix and Maria Yeda Lima and Rafael Roberto and Veronica Teichrieb},
  year={2020},
  month={06},
  publisher={WIPO (PCT)},
  number={WO2021211105A1},
  note={Application filed by Hewlett-Packard Development Company, L.P., Universidade Federal De Pernambuco - Ufpe},
  weblink = {https://patents.google.com/patent/WO2021211105A1/en},
  img = {images/paper_thumbnails/souza_patent20.png}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@misc{souza19,
  title={Neural networks to provide images to recognition engines},
  author={Thiago Souza and Francisco Simões and Thiago Chaves and Heitor Felix and Lucas Albuquerque and Kelvin Cunha and Rafael Roberto and João Teixeira and João Lima and Veronica Teichrieb and Lucio Cossio},
  year={2019},
  month={06},
  publisher={WIPO (PCT)},
  number={WO2021126268A1},
  note={Application filed by Hewlett-Packard Development Company, L.P., Universidade Federal De Pernambuco - Ufpe},
  weblink = {https://patents.google.com/patent/WO2021126268A1/en},
  img = {images/paper_thumbnails/souza_patent19.png}
}

%% 2018 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@misc{henriques18,
  title={Determination of modeling accuracy between three-dimensional object representations},
  author={Diogo Henriques and Francisco Simões and Silvio Melo and André Silva and Thiago Chaves and Gustavo Charamba and João Teixeira and Veronica Teichrieb and Gutenberg Barros and Walter Correia and Thiago Domingues and Vinícius Castilho and Scott White and Marcelo Riss},
  year={2018},
  month={10},
  publisher={WIPO (PCT)},
  number={WO2020091745A1},
  note={Application filed by Hewlett-Packard Development Company, L.P., Universidade Federal De Pernambuco - Ufpe},
  weblink = {https://patents.google.com/patent/WO2020091745A1/en},
  img = {images/paper_thumbnails/henriques_accuracy_patent18.png}
}

@misc{figueiredo18,
  title={Read curved visual marks},
  author={Lucas Figueiredo and João Teixeira and João Lima and Lucas Maggi and Thiago Chaves and Francisco Simões and Lucas Albuquerque and Veronica Teichrieb and Lucio Cossio},
  year={2018},
  month={06},
  publisher={WIPO (PCT)},
  number={WO2020131077A1},
  note={Application filed by Hewlett-Packard Development Company, L.P., Universidade Federal De Pernambuco - Ufpe},
  weblink = {https://patents.google.com/patent/WO2020131077A1/en},
  img = {images/paper_thumbnails/figueiredo_patent18.png}
}

@misc{melo18,
  title={Determine sample points on slices from nurbs models},
  author={Silvio Melo and Francisco Simões and Veronica Teichrieb and Diogo Henriques and Walter Correia and Gutenberg Barros and João Teixeira and Marcelo Riss and Scott White},
  year={2018},
  publisher={WIPO (PCT)},
  number={WO2019152027A1},
  note={Application filed by Hewlett-Packard Development Company, L.P., Universidade Federal De Pernambuco - Ufpe},
  weblink = {https://patents.google.com/patent/WO2019152027A1/en},
  img = {images/paper_thumbnails/melo_patent18.png}
}

@misc{melo_2_18,
  title={Arc segments for three dimensional printers},
  author={Silvio Melo and Diogo Henriques and Francisco Simões and Gutenberg Barros and André Silva and Veronica Teichrieb and Walter Correia and Thiago Chaves and Gustavo Charamba and Thiago Domingues and Vinícius Castilho and Marcelo Riss and Scott White},
  year={2018},
  month={12},
  publisher={WIPO (PCT)},
  number={WO2020122895A1},
  note={Application filed by Hewlett-Packard Development Company, L.P., Universidade Federal De Pernambuco - Ufpe},
  weblink = {https://patents.google.com/patent/WO2020122895A1/en},
  img = {images/paper_thumbnails/melo_arc_patent18.png}
}

%% 2017 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{lima_eswa17,
  title = {Markerless tracking system for augmented reality in the automotive industry},
  journal = ESWA,
  year = {2017},
  author = {João Paulo Lima and Rafael Roberto and Francisco Simões and Mozart Almeida and Lucas Figueiredo and João Teixeira and Veronica Teichrieb},
  img = {images/paper_thumbnails/lima_eswa17.jpg},
  weblink = {https://www.sciencedirect.com/science/article/pii/S0957417417302221}
}

%% 2016 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{lima_mva16,
  title = {Depth-assisted rectification for real-time object detection and pose estimation},
  journal = MVA,
  year = {2016},
  author = {João Paulo Lima and Francisco Simões and Hideaki Uchiyama and Veronica Teichrieb and Eric Marchand},
  img = {images/paper_thumbnails/lima_mva16.jpg},
  weblink = {https://doi.org/10.1007/s00138-015-0740-8}
}

%% 1998 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

